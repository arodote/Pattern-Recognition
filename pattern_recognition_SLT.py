# -*- coding: utf-8 -*-
"""Pattern_recognition_Phoenix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dFqYIFLrL6qAEC2ew-AM1AGdyNj_MquW
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

from tensorflow import keras

import numpy as np
import cv2
import os

#Importing the classes and the alignment
dirNameFiles = "/content/drive/My Drive/Phoenix/"
all_labels = {}
alignment = {}
with open(dirNameFiles + "trainingClasses.txt") as f:
  first_line = f.readline()
  for line in f:
      (val, key) = line.split(" ")
      all_labels[int(key)] = val


with open(dirNameFiles + "train_alignment.txt") as f:
  for line in f:
      (key, val) = line.split(" ")
      alignment[key.split("train/")[1]] = val

#Receives a folder name and a set of lists. Reads all the images and stores them on the lists.
def extractData(folderName, data, dataLabels, dataByVideo, dataByVideoLabels, ourLabels):
  
  width = 105
  height = 130

  # dsize
  dsize = (width, height)
  video = []
  lb = []
  currentLabel = -1
  for frame in sorted(os.listdir(folderName)):
    image=cv2.imread(folderName + frame)
    #image_resized = cv2.resize(image[10: 235, 60: 276], (299, 299), 0, 0, cv2.INTER_LINEAR)
    image = cv2.resize(image, dsize)
    image = image.astype(np.float32)
    image = np.multiply(image, 1.0 / 255.0)
    data.append(image)
    currentLabel = alignment[(folderName + frame).split("/content/drive/My Drive/Phoenix/Dataset/")[1]].rstrip()
    dataLabels.append(currentLabel)

    if(currentLabel not in ourLabels.values()):
      ourLabels[len(ourLabels)] = currentLabel

    video.append(image)
    lb.append(currentLabel)
    

  dataByVideo.append(video)
  dataByVideoLabels.append(lb)
  return data, dataLabels, dataByVideo, dataByVideoLabels, ourLabels

dirName = "/content/drive/My Drive/Phoenix/Dataset/"
ourLabels = {}
data = []
dataLabels = []
dataByVideo = []
dataByVideoLabels = []
for folder in os.listdir(dirName):
  data, dataLabels, dataByVideo, dataByVideoLabels, ourLabels = extractData(dirName + folder + "/1/", data, dataLabels, dataByVideo, dataByVideoLabels, ourLabels)
  print(folder)

def update_labels(dataLabels):
  dataLabels2 = []
  for lb in dataLabels:
    if(lb in ourLabels.values()):
      lb=list(ourLabels.keys())[list(ourLabels.values()).index(lb)]
      dataLabels2.append(lb)
  return dataLabels2

#processing of the data (transform to arrays, shuffling, update labels)
from sklearn.utils import shuffle
numberLabels = len(ourLabels)
print(numberLabels)
print(len(dataLabels))
dataLabels = update_labels(dataLabels)
dataByVideoLabelsAux = []
for video in dataByVideoLabels:
  video = update_labels(video)
  dataByVideoLabelsAux.append(video)
print(dataLabels)
dataByVideoLabels= dataByVideoLabelsAux
data=np.array(data)
dataLabels=np.array(dataLabels)
dataByVideo=np.array(dataByVideo)
dataByVideoLabels=np.array(dataByVideoLabels)
print(data.shape)
print(dataLabels.shape)
print(dataByVideo.shape)
print(dataByVideoLabels.shape)
data, dataLabels = shuffle(data, dataLabels)

from keras.applications.inception_v3 import InceptionV3
from keras.layers import Input

def createInception():
  
  return InceptionV3(weights='imagenet', include_top=False, input_shape=(130, 105,3))

#Inception-v3 without top layers
inceptionModel = createInception()
inceptionModel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
dataTuned = inceptionModel.predict(data)

#CNN model to train a Dense layer
from keras import models, layers, optimizers

def createCNN():
  model = models.Sequential()
  model.add(layers.Dense(256, activation="relu", input_dim=2*1*2048))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(numberLabels, activation="softmax"))

  return model

model = createCNN()

adamN=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)
#opt = optimizers.SGD(lr=0.01)
model.compile(optimizer= adamN, loss='sparse_categorical_crossentropy', metrics=['acc'])
print(dataTuned.shape)
dataTuned = dataTuned.reshape(len(dataTuned), 2*1*2048)
model.fit(dataTuned, dataLabels, validation_split=0.2, epochs=200, batch_size=256)

# The CNN model of our project
def createModifiedInception(inceptionModel, newLayer):

  model = models.Sequential()
  model.add(inceptionModel)
  model.add(layers.Flatten())
  model.add(newLayer)

  return model

#Generate sequences of frames
import math
newInception = createModifiedInception(inceptionModel, model.layers[0])
newInception.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
wrongNum = []
videosByFeatures = []
num = 0

for video in dataByVideo:
  ratio=-1
  video = np.array(video)
  print(video.shape)
  print("video %d of %d" %  (num, len(dataByVideo)))
  num += 1
  videoByFeatures = newInception.predict(video)
  print(videoByFeatures.shape)
  if len(videoByFeatures) > 84:
    ratio = math.floor(len(videoByFeatures)/84)
    print(ratio)
    newList = []
    counter = 0
    for frame in videoByFeatures:
      if(counter% ratio ==0 and len(newList) < 84):
        newList.append(frame)
      counter+=1
  else:
    print("ERROR")
  newList=np.array(newList)
  print(newList.shape)
  videoByFeatures = newList
  wrongNum.append(ratio)
  videosByFeatures.append(videoByFeatures)

videosByFeatures = np.array(videosByFeatures)
print(videosByFeatures.shape)

newLabelList = []
newLb = []
count = 0
counter = 0
for lb in dataByVideoLabels:
  ratio=wrongNum[count]
  if(ratio == -1):
    continue
  else:
    for label in lb:
      if(counter% ratio ==0 and len(newLabelList) < 84):
        newLabelList.append(label)
      counter+=1
  newLb.append(newLabelList)

newLb = np.array(newLb)

print(newLb)

print(dataByVideoLabels.shape)
print(videosByFeatures.shape)
lbFit = newLb.reshape(len(dataByVideoLabels),84,1)

# The RNN model of our project
def createRNN():
  model = models.Sequential()
  model.add(layers.Bidirectional(layers.LSTM(1000, input_shape=(84, 256),return_sequences=True)))
  model.add(layers.Bidirectional(layers.LSTM(1000, input_shape=(84, 256),return_sequences=True)))
 # model.add((layers.LSTM(200,return_sequences=True)))
  model.add(layers.TimeDistributed(layers.Dense(numberLabels, activation='softmax')))
  return model

rnn = createRNN()
rnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
               metrics=['accuracy'])
rnn.fit(videosByFeatures, lbFit, epochs=10, batch_size=4,validation_split= 0.2)

# Similar procedure to the one used with the training data

def extractDataTest(folderName, dataTestByVideo, dataTestByVideoLabels):
  video = []
  width = 105
  height = 130

  # dsize
  dsize = (width, height)
  lb = []
  currentLabel = -1
  for frame in sorted(os.listdir(folderName)):
    image=cv2.imread(folderName + frame)
    #image_resized = cv2.resize(image[10: 235, 60: 276], (299, 299), 0, 0, cv2.INTER_LINEAR)
    image = cv2.resize(image, dsize)
    image = image.astype(np.float32)
    image = np.multiply(image, 1.0 / 255.0)
    currentLabel = alignment[(folderName + frame).split("/content/drive/My Drive/Phoenix/test/")[1]].rstrip()
    if(currentLabel in ourLabels.values()):
      video.append(image)
      lb.append(currentLabel)
    

  dataTestByVideo.append(video)
  dataTestByVideoLabels.append(lb)
  return dataTestByVideo, dataTestByVideoLabels

def update_labels_test(dataTestLabels):
  dataTestLabels2 = []
  for lb in dataTestLabels:
    if(lb in ourLabels.values()):
      lb=list(ourLabels.keys())[list(ourLabels.values()).index(lb)]
      dataTestLabels2.append(lb)
  return dataTestLabels2


dataTestByVideo=[]
dataTestByVideoLabels=[]
dirNameTest = "/content/drive/My Drive/Phoenix/test/"
for folder in os.listdir(dirNameTest):
  dataTestByVideo, dataTestByVideoLabels = extractDataTest(dirNameTest + folder + "/1/", dataTestByVideo, dataTestByVideoLabels)
  print(folder)

from sklearn.utils import shuffle
dataTestByVideoLabelsAux = []
for video in dataTestByVideoLabels:
  video = update_labels_test(video)
  dataTestByVideoLabelsAux.append(video)
dataTestByVideoLabels= dataTestByVideoLabelsAux
dataTestByVideo=np.array(dataTestByVideo)
dataTestByVideoLabels=np.array(dataTestByVideoLabels)
print(dataTestByVideo.shape)
print(dataTestByVideoLabels.shape)

#generate sequences
import math
wrongNum = []
videosTestByFeatures = []
num = 0

for video in dataTestByVideo:
  ratio=-1
  video = np.array(video)
  print(video.shape)
  print("video %d of %d" %  (num, len(dataTestByVideo)))
  num += 1
  videoByFeatures = newInception.predict(video)
  print(videoByFeatures.shape)
  if len(videoByFeatures) > 84:
    ratio = math.floor(len(videoByFeatures)/84)
    print(ratio)
    newListTest = []
    counter = 0
    for frame in videoByFeatures:
      if(counter% ratio ==0 and len(newListTest) < 84):
        newListTest.append(frame)
      counter+=1
  else:
    print("ERROR")

  newListTest=np.array(newListTest)
  print(newListTest.shape)
  videoByFeatures = newListTest
  wrongNum.append(ratio)
  videosTestByFeatures.append(videoByFeatures)

videosTestByFeatures = np.array(videosTestByFeatures)
print(videosTestByFeatures.shape)

newLabelListTest = []
newLbTest = []
count = 0
counter = 0
for lb in dataTestByVideoLabels:
  ratio=wrongNum[count]
  if(ratio == -1):
    continue
  else:
    for label in lb:
      if(counter% ratio ==0 and len(newLabelListTest) < 84):
        newLabelListTest.append(label)
      counter+=1
  newLbTest.append(newLabelListTest)

newLbTest = np.array(newLbTest)
TestLabels = newLbTest.reshape(len(videosTestByFeatures),84,1)
print(newLbTest.shape)

rnn.evaluate(videosTestByFeatures, TestLabels)

prediction = rnn.predict(videosTestByFeatures)